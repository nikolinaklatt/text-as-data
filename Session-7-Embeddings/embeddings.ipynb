{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.038194</td>\n",
       "      <td>-0.244870</td>\n",
       "      <td>0.72812</td>\n",
       "      <td>-0.399610</td>\n",
       "      <td>0.083172</td>\n",
       "      <td>0.043953</td>\n",
       "      <td>-0.391410</td>\n",
       "      <td>0.334400</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>-0.017099</td>\n",
       "      <td>-0.389840</td>\n",
       "      <td>0.87424</td>\n",
       "      <td>-0.72569</td>\n",
       "      <td>-0.51058</td>\n",
       "      <td>-0.520280</td>\n",
       "      <td>-0.14590</td>\n",
       "      <td>0.82780</td>\n",
       "      <td>0.270620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.107670</td>\n",
       "      <td>0.110530</td>\n",
       "      <td>0.59812</td>\n",
       "      <td>-0.543610</td>\n",
       "      <td>0.673960</td>\n",
       "      <td>0.106630</td>\n",
       "      <td>0.038867</td>\n",
       "      <td>0.354810</td>\n",
       "      <td>0.06351</td>\n",
       "      <td>-0.094189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349510</td>\n",
       "      <td>-0.722600</td>\n",
       "      <td>0.375490</td>\n",
       "      <td>0.44410</td>\n",
       "      <td>-0.99059</td>\n",
       "      <td>0.61214</td>\n",
       "      <td>-0.351110</td>\n",
       "      <td>-0.83155</td>\n",
       "      <td>0.45293</td>\n",
       "      <td>0.082577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.339790</td>\n",
       "      <td>0.209410</td>\n",
       "      <td>0.46348</td>\n",
       "      <td>-0.647920</td>\n",
       "      <td>-0.383770</td>\n",
       "      <td>0.038034</td>\n",
       "      <td>0.171270</td>\n",
       "      <td>0.159780</td>\n",
       "      <td>0.46619</td>\n",
       "      <td>-0.019169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063351</td>\n",
       "      <td>-0.674120</td>\n",
       "      <td>-0.068895</td>\n",
       "      <td>0.53604</td>\n",
       "      <td>-0.87773</td>\n",
       "      <td>0.31802</td>\n",
       "      <td>-0.392420</td>\n",
       "      <td>-0.23394</td>\n",
       "      <td>0.47298</td>\n",
       "      <td>-0.028803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.152900</td>\n",
       "      <td>-0.242790</td>\n",
       "      <td>0.89837</td>\n",
       "      <td>0.169960</td>\n",
       "      <td>0.535160</td>\n",
       "      <td>0.487840</td>\n",
       "      <td>-0.588260</td>\n",
       "      <td>-0.179820</td>\n",
       "      <td>-1.35810</td>\n",
       "      <td>0.425410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187120</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.267570</td>\n",
       "      <td>0.72700</td>\n",
       "      <td>-0.59363</td>\n",
       "      <td>-0.34839</td>\n",
       "      <td>-0.560940</td>\n",
       "      <td>-0.59100</td>\n",
       "      <td>1.00390</td>\n",
       "      <td>0.206640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-0.189700</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>0.19084</td>\n",
       "      <td>-0.049184</td>\n",
       "      <td>-0.089737</td>\n",
       "      <td>0.210060</td>\n",
       "      <td>-0.549520</td>\n",
       "      <td>0.098377</td>\n",
       "      <td>-0.20135</td>\n",
       "      <td>0.342410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131340</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>-0.318690</td>\n",
       "      <td>-0.61419</td>\n",
       "      <td>-0.62393</td>\n",
       "      <td>-0.41548</td>\n",
       "      <td>-0.038175</td>\n",
       "      <td>-0.39804</td>\n",
       "      <td>0.47647</td>\n",
       "      <td>-0.159830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2        3         4         5         6         7    \\\n",
       "0                                                                          \n",
       "the -0.038194 -0.244870  0.72812 -0.399610  0.083172  0.043953 -0.391410   \n",
       ",   -0.107670  0.110530  0.59812 -0.543610  0.673960  0.106630  0.038867   \n",
       ".   -0.339790  0.209410  0.46348 -0.647920 -0.383770  0.038034  0.171270   \n",
       "of  -0.152900 -0.242790  0.89837  0.169960  0.535160  0.487840 -0.588260   \n",
       "to  -0.189700  0.050024  0.19084 -0.049184 -0.089737  0.210060 -0.549520   \n",
       "\n",
       "          8        9         10   ...       91        92        93       94   \\\n",
       "0                                 ...                                          \n",
       "the  0.334400 -0.57545  0.087459  ...  0.016215 -0.017099 -0.389840  0.87424   \n",
       ",    0.354810  0.06351 -0.094189  ...  0.349510 -0.722600  0.375490  0.44410   \n",
       ".    0.159780  0.46619 -0.019169  ... -0.063351 -0.674120 -0.068895  0.53604   \n",
       "of  -0.179820 -1.35810  0.425410  ...  0.187120 -0.018488 -0.267570  0.72700   \n",
       "to   0.098377 -0.20135  0.342410  ... -0.131340  0.058617 -0.318690 -0.61419   \n",
       "\n",
       "         95       96        97       98       99        100  \n",
       "0                                                            \n",
       "the -0.72569 -0.51058 -0.520280 -0.14590  0.82780  0.270620  \n",
       ",   -0.99059  0.61214 -0.351110 -0.83155  0.45293  0.082577  \n",
       ".   -0.87773  0.31802 -0.392420 -0.23394  0.47298 -0.028803  \n",
       "of  -0.59363 -0.34839 -0.560940 -0.59100  1.00390  0.206640  \n",
       "to  -0.62393 -0.41548 -0.038175 -0.39804  0.47647 -0.159830  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "N_DIMS = 100\n",
    "z = ZipFile(\"embeddings/glove6b/glove.6B.zip\")\n",
    "f = z.open(f'glove.6B.{N_DIMS}d.txt')\n",
    "\n",
    "word_matrix = pd.read_table(\n",
    "    f, sep=\" \", index_col=0, \n",
    "    header=None, quoting=csv.QUOTE_NONE\n",
    ")\n",
    "word_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog</th>\n",
       "      <th>cat</th>\n",
       "      <th>carbon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879808</td>\n",
       "      <td>0.090229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.879808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbon</th>\n",
       "      <td>0.090229</td>\n",
       "      <td>0.050274</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dog       cat    carbon\n",
       "dog     1.000000  0.879808  0.090229\n",
       "cat     0.879808  1.000000  0.050274\n",
       "carbon  0.090229  0.050274  1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "word_list = [\"dog\",\"cat\",\"carbon\"]\n",
    "words = word_matrix.loc[word_list]\n",
    "sims = pd.DataFrame(cosine_similarity(words))\n",
    "sims.index, sims.columns = word_list, word_list\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between 2 words\n",
    "from scipy.spatial.distance import cosine\n",
    "vec_a = word_matrix.loc[\"paris\"]\n",
    "vec_b = word_matrix.loc[\"france\"]\n",
    "1 - cosine(vec_a, vec_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar words to x\n",
    "vec_a = word_matrix.loc[\"cat\"]\n",
    "sims = 1 - word_matrix.apply(cosine, axis=1, args=(vec_a,))\n",
    "sims.sort_values(ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "cat       1.000000\n",
       "dog       0.879808\n",
       "rabbit    0.742443\n",
       "cats      0.732300\n",
       "monkey    0.728871\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for similar words to x\n",
    "def similar_words(word, word_matrix):\n",
    "    vec_a = word_matrix.loc[word]\n",
    "    sims = 1 - word_matrix.apply(cosine, axis=1, args=(vec_a,))\n",
    "    return sims.sort_values(ascending=False)\n",
    "\n",
    "similar_words(\"carbon\",word_matrix).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "germany    0.892766\n",
       "austria    0.762186\n",
       "denmark    0.748199\n",
       "poland     0.745510\n",
       "berlin     0.722017\n",
       "france     0.721111\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = word_matrix.loc[\"paris\"] - word_matrix.loc[\"france\"] \n",
    "vec_d = word_matrix.loc[\"berlin\"] - diff\n",
    "sims = 1 - word_matrix.apply(cosine, axis=1, args=(vec_d,))\n",
    "sims.sort_values(ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "docs = [\n",
    "  \"The acclaimed author penned novels based on her life\",\n",
    "  \"Nobel prize-winning writer writes autobiographical fiction\"\n",
    "]\n",
    "vec = CountVectorizer()\n",
    "dfmat = vec.fit_transform(docs).todense()\n",
    "dfmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acclaimed',\n",
       " 'author',\n",
       " 'autobiographical',\n",
       " 'based',\n",
       " 'fiction',\n",
       " 'her',\n",
       " 'life',\n",
       " 'nobel',\n",
       " 'novels',\n",
       " 'on',\n",
       " 'penned',\n",
       " 'prize',\n",
       " 'the',\n",
       " 'winning',\n",
       " 'writer',\n",
       " 'writes'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7854257726317803"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "common_features = set(word_matrix.index) & set(vec.get_feature_names_out())\n",
    "vocab_ids = [vec.vocabulary_[x] for x in common_features]\n",
    "glove_dfmat = dfmat[:,vocab_ids]\n",
    "corpus_word_matrix = word_matrix.loc[common_features,]\n",
    "doc_matrix = np.inner(glove_dfmat, corpus_word_matrix.T)\n",
    "1 - cosine(doc_matrix[0,], doc_matrix[1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
